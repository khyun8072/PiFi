 2025-01-25 13:03:09 - Start training from epoch 0
 2025-01-25 13:03:10 - TRAIN - Epoch [0 / 3] - Iter[0 / 8972] - Loss: 135.8152
Training - Epoch [0/3]:   0%|                                                                         | 0/8972 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.46 `position_ids` will be removed and `position_embeddings` will be mandatory.
Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.
































































































































































Training - Epoch [0/3]:   6%|███▍                                                         | 500/8972 [07:38<4:10:00,  1.77s/it]






























































































































































Training - Epoch [0/3]:  11%|██████▋                                                     | 1000/8972 [15:15<4:00:10,  1.81s/it]































































































































































Training - Epoch [0/3]:  17%|██████████                                                  | 1501/8972 [22:53<2:57:43,  1.43s/it]































































































































































Training - Epoch [0/3]:  22%|█████████████▎                                              | 2000/8972 [30:30<3:28:22,  1.79s/it]



































































































































































Training - Epoch [0/3]:  28%|████████████████▋                                           | 2502/8972 [38:11<2:01:41,  1.13s/it]






























































































































































Training - Epoch [0/3]:  33%|████████████████████                                        | 3000/8972 [45:46<3:02:18,  1.83s/it]
































































































































































Training - Epoch [0/3]:  39%|███████████████████████▍                                    | 3503/8972 [53:24<1:25:14,  1.07it/s]
































































































































































Training - Epoch [0/3]:  45%|█████████████████████████▊                                | 4002/8972 [1:01:01<1:33:27,  1.13s/it]
































































































































































Training - Epoch [0/3]:  50%|█████████████████████████████                             | 4500/8972 [1:08:38<2:12:29,  1.78s/it]






























































































































































Training - Epoch [0/3]:  56%|█████████████████████████████████▍                          | 4999/8972 [1:16:12<35:34,  1.86it/s]





























































































































































Training - Epoch [0/3]:  61%|████████████████████████████████████▊                       | 5499/8972 [1:23:49<31:10,  1.86it/s]



































































































































































Training - Epoch [0/3]:  67%|██████████████████████████████████████▊                   | 6001/8972 [1:31:32<1:10:02,  1.41s/it]



























































































































































Training - Epoch [0/3]:  72%|███████████████████████████████████████████▍                | 6501/8972 [1:39:09<58:59,  1.43s/it]































































































































































Training - Epoch [0/3]:  78%|█████████████████████████████████████████████▎            | 7000/8972 [1:46:48<1:01:14,  1.86s/it]




























































































































































Training - Epoch [0/3]:  84%|██████████████████████████████████████████████████▏         | 7501/8972 [1:54:26<35:48,  1.46s/it]




























































































































































Training - Epoch [0/3]:  89%|█████████████████████████████████████████████████████▌      | 8001/8972 [2:02:03<22:59,  1.42s/it]






























































































































































Training - Epoch [0/3]:  95%|████████████████████████████████████████████████████████▊   | 8502/8972 [2:09:39<08:40,  1.11s/it]




















































































































































Training - Epoch [0/3]: 100%|████████████████████████████████████████████████████████████| 8972/8972 [2:16:46<00:00,  1.09it/s]
Validating - Epoch [0 / 3]:   0%|▏                                                             | 1/417 [00:00<03:02,  2.28it/s]

Validating - Epoch [0 / 3]:   2%|█                                                             | 7/417 [00:01<01:20,  5.10it/s]






































































Validating - Epoch [0 / 3]:  99%|███████████████████████████████████████████████████████████▍| 413/417 [04:12<00:01,  2.50it/s]
 2025-01-25 15:24:09 - VALID - Epoch [0 / 3] - Iter [416 / 417] - Loss: 2.6381

Validating - Epoch [0 / 3]: 100%|████████████████████████████████████████████████████████████| 417/417 [04:13<00:00,  1.65it/s]
 2025-01-25 15:24:43 - VALID - Best valid at epoch 0 - loss: 2.4530
 2025-01-25 15:24:43 - VALID - Saved checkpoint to /nas_homes/kyeonghyun/model_checkpoint/PiFi_Generation/summarization/cnn_dailymail/t5/base_llm/llama3.1/0
Training - Epoch [1/3]:   0%|                                                                         | 0/8972 [00:00<?, ?it/s]



































































































































































Training - Epoch [1/3]:   6%|███▍                                                         | 500/8972 [07:40<1:18:59,  1.79it/s]
































































































































































Training - Epoch [1/3]:  11%|██████▋                                                     | 1000/8972 [15:18<1:14:15,  1.79it/s]


































































































































































Training - Epoch [1/3]:  17%|██████████                                                  | 1500/8972 [22:55<1:08:53,  1.81it/s]
































































































































































Training - Epoch [1/3]:  22%|█████████████▎                                              | 2000/8972 [30:31<1:04:25,  1.80it/s]

































































































































































Training - Epoch [1/3]:  28%|████████████████▋                                           | 2502/8972 [38:12<2:30:38,  1.40s/it]
































































































































































Training - Epoch [1/3]:  33%|████████████████████                                        | 3001/8972 [45:49<2:58:46,  1.80s/it]
































































































































































Training - Epoch [1/3]:  39%|███████████████████████▍                                    | 3501/8972 [53:26<2:41:15,  1.77s/it]


































































































































































Training - Epoch [1/3]:  45%|█████████████████████████▉                                | 4003/8972 [1:01:04<1:31:07,  1.10s/it]

































































































































































Training - Epoch [1/3]:  50%|██████████████████████████████                              | 4500/8972 [1:08:36<41:35,  1.79it/s]






























































































































































Training - Epoch [1/3]:  56%|█████████████████████████████████▍                          | 5000/8972 [1:16:10<36:48,  1.80it/s]



































































































































































Training - Epoch [1/3]:  61%|████████████████████████████████████▊                       | 5500/8972 [1:23:47<32:09,  1.80it/s]


















Training - Epoch [1/3]:  62%|█████████████████████████████████████▏                      | 5553/8972 [1:24:39<52:07,  1.09it/s]
Traceback (most recent call last):
  File "main.py", line 49, in <module>
    main(args)
  File "main.py", line 40, in main
    job(args)
  File "/home/kyeonghyun/PiFi/Generation/task/summarization/train.py", line 129, in training
    batch_loss_cls.backward()
  File "/home/kyeonghyun/anaconda3/envs/khyun/lib/python3.8/site-packages/torch/_tensor.py", line 522, in backward
    torch.autograd.backward(
  File "/home/kyeonghyun/anaconda3/envs/khyun/lib/python3.8/site-packages/torch/autograd/__init__.py", line 266, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt